(window.webpackJsonp=window.webpackJsonp||[]).push([[7],{JfeM:function(e,t,n){"use strict";n.r(t),n.d(t,"newquery",(function(){return l}));var a=n("q1tI"),o=n.n(a),r=n("8k0H"),i=n("hSb8");t.default=function(e){var t=e.data;return o.a.createElement(r.a,null,o.a.createElement("div",null,o.a.createElement("h1",null," Line tracking for a moving robot "),o.a.createElement(i.a,{singleitem:t.homeJson.AGV_single}),o.a.createElement("h2",null," Why line tracking ? "),"Here we are going to learn how to use a camera to follow a line drawn on the floor. Let’s say that you want to conceive an autonomous robot but you’re not ready to use mapping technologies to guide it yet. Then line tracking would be a nice and simple way to test your robot. To track lines, you will need a camera and a numeric software such as Matlab or Labview.",o.a.createElement("h2",null,"See the line"),o.a.createElement("ul",null,o.a.createElement("li",null,"Step 1 : Get a picture"),"You can either take a picture or directly establish streaming, it’s up to you.",o.a.createElement(i.a,{singleitem:t.homeJson.AGV_t1}),"Get a picture of your line",o.a.createElement("li",null," Step 2 : Get access to the RGB data "),"RGB (Red Green Blue) are 3 indexes of a pixel’s colour, usually each is defined from 0 to 255. You will need to get the RGB code of every pixel of your screen and read the average RGB value of the line you want to track. For example, perfect red is [255 , 0 , 0], perfect green is [0 , 255 , 0] and a mix would look like [125 , 125 , 0].",o.a.createElement(i.a,{singleitem:t.homeJson.AGV_t2}),"“Read” your line’s RGB code",o.a.createElement("li",null,"Step 3 : Get the coordinates of the pixels"),"Now that you know the colour indexes you’re looking for, you can get the coordinates of all the pixels whose RGB values match with your line.",o.a.createElement(i.a,{singleitem:t.homeJson.AGV_t3}),"Consider each pixel as its coordinates Unfortunately, it is very rare that a single RGB measure matches the entire line so you can introduce a threshold admission to be sure of it. For example if two pixels of your red line are respectively corresponding to RGB = [240 , 5 , 2] and RGB = [251 , 15 , 1], you may choose all the pixels whose RGBs are defined between [245±5 , 10±5 , 1].",o.a.createElement(i.a,{singleitem:t.homeJson.AGV_t4}),"Select the coordinates",o.a.createElement("li",null,"Step 4 : See the line"),"Compute the coefficients of the least square line associated to the pixel coordinates you’ve found.",o.a.createElement(i.a,{singleitem:t.homeJson.AGV_t5}),o.a.createElement("h2",null,"Track the line"),o.a.createElement("li",null,"Step 1 : Define what you are looking for"),"Usually, you need to follow the line straight, which means you want to keep the line centered and vertical. In order to regulate it you will need : The distance between the line and the center of the screen D. D=(|a*xcenter + b*ycenter +c|)/((a2+b2)^(1/2)) The orientation of the line α. α = atan(-a/b)",o.a.createElement("li",null,"Step 2 : Implement automatic control")," "),"Depending on your robot/vehicle, you will need to implement different automatic controls to monitor your motors. For “classical” applications such as wheeled robots you can configure it at low speed by implementing a Full State Feedback if you can model your system and get the following State space equations. The LQ controller fits particularly well here.","Measurement equation Where x is a state vector, y is the output vector and u is the control vector. In this case y represents our motors inputs, u includes D and α, and x may correspond to y and other variables you want to estimate in your model. However if you are not familiar with State Feedbacks, you can also implement a simple feedback loop with an adjusted proportional gain, it will already work just fine but you will still have to regulate the weighting between the distance factor D and the orientation factor α depending on your system performances against it. Here is an example of a line tracking establishment I achieved at AKEOPLUS:"))};var l="3904383177"},hSb8:function(e,t,n){"use strict";var a=n("q1tI"),o=n.n(a),r=n("9eSz"),i=n.n(r),l=n("MUpH"),c=n("vOnD"),u=n("WveJ");function s(){var e=Object(l.a)(["\n    margin-bottom: 4rem;\n  "]);return s=function(){return e},e}function m(){var e=Object(l.a)(["\n  color: #757575;\n  margin: 0 2rem 2rem;\n\n  ",";\n"]);return m=function(){return e},e}function d(){var e=Object(l.a)(["\n  display: block;\n  font-size: 2rem;\n  font-weight: 500;\n  margin: 2rem 2rem 1rem;\n"]);return d=function(){return e},e}c.b.span(d()),c.b.p(m(),u.a.TABLET(s()));var h=function(e){var t=e.title,n=(e.copy,e.image);return o.a.createElement("figure",null,"    ",o.a.createElement(i.a,{fluid:n?n.childImageSharp.fluid:{},alt:t}),o.a.createElement("figcaption",null,"    "))};function f(){var e=Object(l.a)(["\n    display: block;\n  "]);return f=function(){return e},e}function p(){var e=Object(l.a)(["\n  display: grid;\n  grid-template-columns: minmax(400px, max-content);\n  grid-gap: 1rem;\n  padding: 0 4rem;\n  margin: 1rem 0;\n\n  ",";\n"]);return p=function(){return e},e}var y=c.b.div(p(),u.a.TABLET(f()));t.a=function(e){var t=e.singleitem;return o.a.createElement(y,null,o.a.createElement(h,t))}}}]);
//# sourceMappingURL=component---src-pages-agv-jsx-3367381d19965fa9b2dc.js.map